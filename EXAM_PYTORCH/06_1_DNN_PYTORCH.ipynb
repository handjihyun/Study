{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03501580",
   "metadata": {},
   "source": [
    "### ✨활성화 함수\n",
    "- 주요 활성화 함수\n",
    "    - 시그모이드 함수 : nn.Sigmoid()\n",
    "    - ReLU 함수 : nn.ReLU()\n",
    "    - Leaky ReLU 함수 : nn.LeakyReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e545300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.activation = nn.Sigmoid() # 시그모이드 함수\n",
    "        # self.activation = nn.LeakyReLU(0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.activation(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f3f2f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(4)\n",
    "y = torch.zeros(3)\n",
    "model = LinearRegressionModel(4, 3)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314905d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "nb_epochs = 1000\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "    y_pred = model(x)\n",
    "    loss = loss_function(y_pred, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e01110f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[-0.2139, -0.7097,  0.0569, -0.8059],\n",
      "        [-0.4430, -0.6965, -0.3392,  0.1508],\n",
      "        [-0.8683, -0.0714, -0.4342, -0.3089]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0367, -0.3654,  0.0231], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb95ae8",
   "metadata": {},
   "source": [
    "### ✨다층 레이어 구현\n",
    "- input layer -> hidden layer -> output layer 순으로 작성\n",
    "- activation function 적용은 output layer에는 적용하지 않는 것이 일반적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5684b929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, 10)\n",
    "        self.linear2 = nn.Linear(10, 10)\n",
    "        self.linear3 = nn.Linear(10, 10)\n",
    "        self.linear4 = nn.Linear(10, output_dim)\n",
    "        self.activation = nn.LeakyReLU(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hidden = self.activation(self.linear1(x))\n",
    "        hidden = self.activation(self.linear2(hidden))\n",
    "        hidden = self.activation(self.linear3(hidden))\n",
    "        y = self.linear4(hidden)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45c6852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(4)\n",
    "y = torch.zeros(3)\n",
    "model = LinearRegressionModel(4, 3)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "280573c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "nb_epochs = 1000\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "    y_pred = model(x)\n",
    "    loss = loss_function(y_pred, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "684c2890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.6739e-11, grad_fn=<MseLossBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1389,  0.1026, -0.4651, -0.3142],\n",
      "        [-0.2240,  0.4407,  0.0532,  0.3024],\n",
      "        [ 0.1379, -0.4305, -0.0043, -0.1019],\n",
      "        [-0.1317, -0.1706,  0.2142,  0.3331],\n",
      "        [-0.1119,  0.3032, -0.3819,  0.2917],\n",
      "        [ 0.1023, -0.0334, -0.4315, -0.4222],\n",
      "        [ 0.2257, -0.0095,  0.1118, -0.4338],\n",
      "        [ 0.4957, -0.2891, -0.0560, -0.3820],\n",
      "        [ 0.2727, -0.4982,  0.3680,  0.3386],\n",
      "        [ 0.3361, -0.3046, -0.4299,  0.4957]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4683,  0.3656,  0.1940, -0.2059, -0.0510,  0.4191, -0.0126, -0.1036,\n",
      "        -0.1953, -0.2730], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1302,  0.2372, -0.1786,  0.2355,  0.0726, -0.2157, -0.0991,  0.0952,\n",
      "         -0.2556,  0.0239],\n",
      "        [-0.0883,  0.2224, -0.1213, -0.1631, -0.0672, -0.0076, -0.2234, -0.2663,\n",
      "          0.1261,  0.2796],\n",
      "        [-0.0761, -0.2767,  0.0496, -0.2582, -0.2831,  0.1996, -0.2972,  0.1804,\n",
      "         -0.2493, -0.1068],\n",
      "        [-0.2266, -0.3086,  0.2431,  0.1998, -0.0504,  0.2645, -0.2590,  0.2305,\n",
      "          0.1617, -0.0442],\n",
      "        [-0.2841,  0.1763,  0.0411, -0.2486,  0.2952,  0.2965,  0.3121,  0.2947,\n",
      "         -0.0582, -0.0741],\n",
      "        [-0.3000, -0.1301,  0.1235, -0.2238, -0.0602,  0.1804, -0.1893,  0.1486,\n",
      "         -0.0172, -0.2698],\n",
      "        [ 0.1799, -0.2501, -0.1139,  0.1360, -0.1035, -0.0248,  0.1971, -0.0201,\n",
      "          0.2168, -0.0496],\n",
      "        [ 0.2107,  0.1293,  0.2876,  0.2942, -0.1482,  0.2498,  0.2908, -0.2099,\n",
      "          0.2050,  0.2535],\n",
      "        [ 0.2761, -0.0385, -0.2116, -0.2536,  0.1369, -0.3096, -0.1412, -0.2351,\n",
      "         -0.2172,  0.1966],\n",
      "        [-0.0196, -0.0772,  0.0289, -0.1640,  0.2399, -0.2418,  0.1163, -0.2010,\n",
      "          0.1016, -0.0274]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0592,  0.2207,  0.1735, -0.1619,  0.2539,  0.0150,  0.2503, -0.1555,\n",
      "        -0.1108,  0.0214], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0531,  0.2861, -0.1103, -0.2388, -0.0858,  0.1127, -0.1695, -0.1181,\n",
      "          0.0945, -0.1067],\n",
      "        [-0.0173,  0.2024,  0.2139, -0.2441,  0.2334,  0.3013,  0.3008,  0.2732,\n",
      "         -0.1901, -0.2141],\n",
      "        [-0.2590,  0.1170,  0.0058,  0.2450, -0.0181, -0.1218, -0.1909, -0.2283,\n",
      "         -0.2138, -0.0246],\n",
      "        [-0.2013, -0.0723,  0.0597, -0.2864, -0.1075, -0.0246, -0.2887,  0.0786,\n",
      "          0.1294,  0.2215],\n",
      "        [-0.1398,  0.0519, -0.2346,  0.0029,  0.1668,  0.1515, -0.0413,  0.2445,\n",
      "          0.0067,  0.1622],\n",
      "        [ 0.1193, -0.2887,  0.1362,  0.1418,  0.2566,  0.1448,  0.1373, -0.2905,\n",
      "         -0.3046,  0.0554],\n",
      "        [ 0.1734, -0.1783,  0.0318, -0.1582, -0.0388,  0.1919, -0.0171, -0.0630,\n",
      "         -0.2899, -0.1017],\n",
      "        [ 0.1738, -0.1491,  0.1989,  0.0272,  0.0285,  0.0736, -0.0111,  0.0310,\n",
      "         -0.0823, -0.0582],\n",
      "        [-0.1157,  0.2199, -0.0005, -0.0534, -0.0658, -0.0798,  0.1644, -0.0187,\n",
      "         -0.0082,  0.2005],\n",
      "        [ 0.2582,  0.0063, -0.2684,  0.1539,  0.0156,  0.0698, -0.0211, -0.1746,\n",
      "          0.0630, -0.1489]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0147,  0.1164,  0.2818, -0.0734, -0.1504, -0.2006, -0.0094,  0.1978,\n",
      "         0.1442,  0.2363], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0623,  0.0812, -0.2085, -0.2473, -0.2289,  0.0365, -0.2320, -0.0869,\n",
      "         -0.1116,  0.2471],\n",
      "        [-0.1898, -0.0429,  0.1652, -0.0540, -0.1902, -0.2226, -0.1005,  0.2655,\n",
      "         -0.0810,  0.3031],\n",
      "        [ 0.2393, -0.0614,  0.2603, -0.2779, -0.1679,  0.2986, -0.1977,  0.2255,\n",
      "         -0.1593,  0.0575]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0101, -0.1372, -0.0946], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaa8890",
   "metadata": {},
   "source": [
    "### ✨nn.Sequential\n",
    "- nn.Sequential은 순서를 갖는 모듈의 컨테이너를 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91288a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(4)\n",
    "y = torch.zeros(3)\n",
    "\n",
    "input_dim = x.size(0)\n",
    "output_dim = y.size(0)\n",
    "\n",
    "model = nn.Sequential(\n",
    "nn.Linear(input_dim, 10),\n",
    "nn.LeakyReLU(0.1),\n",
    "nn.Linear(10, 10),\n",
    "nn.LeakyReLU(0.1),\n",
    "nn.Linear(10, output_dim)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa5a9bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.8085e-09, grad_fn=<MseLossBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[-1.6592e-01, -4.0879e-01, -1.6137e-01, -5.8060e-02],\n",
      "        [ 5.3031e-02,  6.3167e-02, -2.7856e-01, -2.3568e-01],\n",
      "        [-9.9009e-02, -1.7502e-01,  2.5114e-01, -3.9851e-01],\n",
      "        [-2.1113e-01, -2.9063e-01,  4.2643e-01,  1.6077e-01],\n",
      "        [ 2.3279e-02,  1.6874e-01,  1.0100e-04, -3.3323e-01],\n",
      "        [ 3.8658e-01, -3.7051e-01, -4.8802e-03, -1.3409e-01],\n",
      "        [ 3.3883e-01,  3.5222e-01, -3.3682e-01, -3.2206e-01],\n",
      "        [ 3.6824e-01,  4.2356e-01, -2.8808e-01,  2.9695e-01],\n",
      "        [ 4.2302e-01,  2.8722e-01,  4.9477e-01, -3.2096e-01],\n",
      "        [ 1.9488e-02, -2.3716e-02, -2.9596e-02, -3.5286e-03]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3591,  0.0102, -0.2327, -0.4964, -0.2917, -0.1369, -0.0362, -0.2401,\n",
      "        -0.2351,  0.3620], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0423, -0.0899, -0.0994, -0.1143, -0.1039, -0.3007,  0.2995,  0.2768,\n",
      "         -0.0430, -0.1954],\n",
      "        [-0.1436,  0.0490,  0.2353,  0.0997, -0.2330,  0.2236, -0.1045,  0.0732,\n",
      "          0.0753,  0.1176],\n",
      "        [ 0.2217,  0.1642,  0.2736, -0.2171, -0.2413, -0.0885, -0.3008,  0.1302,\n",
      "         -0.0407, -0.2520],\n",
      "        [-0.2553, -0.1452, -0.0036,  0.2498, -0.3147,  0.1143, -0.1651,  0.1914,\n",
      "          0.0983,  0.1411],\n",
      "        [-0.2237,  0.2975, -0.0409,  0.2569, -0.2097,  0.2322,  0.2321,  0.2644,\n",
      "         -0.2883,  0.0841],\n",
      "        [-0.0557, -0.2449, -0.2310, -0.0762, -0.1508,  0.1937,  0.2377,  0.0553,\n",
      "          0.1548, -0.1649],\n",
      "        [ 0.2884, -0.0527,  0.2391,  0.3139, -0.2211,  0.2914,  0.0998, -0.2394,\n",
      "          0.0021, -0.0608],\n",
      "        [ 0.2277,  0.1632,  0.3099,  0.2125, -0.2016,  0.0073, -0.0650,  0.0803,\n",
      "          0.3293,  0.1564],\n",
      "        [ 0.1729, -0.1465, -0.0331, -0.2713,  0.1912,  0.1557, -0.1878, -0.1476,\n",
      "         -0.2709, -0.0824],\n",
      "        [-0.2153, -0.2119,  0.2926, -0.0275, -0.2625,  0.3145,  0.1269, -0.0997,\n",
      "         -0.2443,  0.2354]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1007,  0.1291,  0.0163, -0.2551, -0.0106, -0.3178, -0.2593, -0.0932,\n",
      "         0.0084, -0.3194], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0966, -0.1757,  0.2165, -0.1337,  0.2580, -0.0486,  0.0649, -0.2020,\n",
      "         -0.1628,  0.1218],\n",
      "        [-0.1478, -0.1837,  0.2599, -0.2070, -0.0218, -0.1399,  0.0985,  0.0751,\n",
      "          0.1339, -0.0737],\n",
      "        [-0.2556, -0.0346, -0.2931,  0.0684,  0.2269, -0.2446,  0.2704,  0.2924,\n",
      "         -0.1976,  0.2537]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0823,  0.0381, -0.0271], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "learning_rate = 0.01\n",
    "nb_epochs = 1000\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "    y_pred = model(x)\n",
    "    loss = loss_function(y_pred, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(loss)\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db85e38d",
   "metadata": {},
   "source": [
    "### ✨SGD 방식 구현\n",
    "- torch.randperm(n) : 0 ~ n-1 까지의 정수를 랜덤하게 섞어서, 순열(배열)을 만들어 줌\n",
    "- torch.index_select(텐서객체, 차원번호, 인덱스텐서)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f39ff286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0967, -0.5852, -0.5123,  1.1497],\n",
      "        [-1.7728, -0.3127,  0.7205,  0.3598],\n",
      "        [-0.2598, -1.0256, -1.7208,  0.4393]])\n",
      "tensor([1, 2])\n",
      "tensor([[-1.7728, -0.3127,  0.7205,  0.3598],\n",
      "        [-0.2598, -1.0256, -1.7208,  0.4393]])\n",
      "tensor([[-0.5852, -0.5123],\n",
      "        [-0.3127,  0.7205],\n",
      "        [-1.0256, -1.7208]])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.randn(3, 4)\n",
    "print(data1)\n",
    "indices = torch.tensor([1, 2])\n",
    "print(indices)\n",
    "print(torch.index_select(data1, 0, indices))\n",
    "print(torch.index_select(data1, 1, indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3df1972",
   "metadata": {},
   "source": [
    "### ✨테스트 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd002df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(5000, 10) # 10개의 feature\n",
    "y = torch.zeros(5000, 1) # 1 output\n",
    "learning_rate = 0.01\n",
    "nb_epochs = 1000\n",
    "minibatch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c807170",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x.size(-1)\n",
    "output_dim = y.size(-1)\n",
    "\n",
    "model = nn.Sequential(\n",
    "nn.Linear(input_dim, 10),\n",
    "nn.LeakyReLU(0.1),\n",
    "nn.Linear(10, 8),\n",
    "nn.LeakyReLU(0.1),\n",
    "nn.Linear(8, 6),\n",
    "nn.LeakyReLU(0.1),\n",
    "nn.Linear(6, output_dim)\n",
    ")\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32eae779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1089, 4926,  931,  ..., 1944,   46,  806])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.randperm(x.size(0)) # 5000개\n",
    "print(indices)\n",
    "\n",
    "x_batch_list = torch.index_select(x, 0, index=indices)\n",
    "y_batch_list = torch.index_select(y, 0, index=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beed6ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "192a1d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20\n"
     ]
    }
   ],
   "source": [
    "x_batch_list = x_batch_list.split(minibatch_size, dim=0)\n",
    "y_batch_list = y_batch_list.split(minibatch_size, dim=0)\n",
    "print(len(x_batch_list), len(y_batch_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afb19015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_batch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9f4cb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_batch_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7fe05dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04a8e918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6043e-14, grad_fn=<MseLossBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1558,  0.1666,  0.3064, -0.3107, -0.1156,  0.0339,  0.1937,  0.1341,\n",
      "         -0.1442,  0.0917],\n",
      "        [ 0.1964,  0.0721,  0.0859, -0.0116, -0.0390, -0.0367,  0.0913, -0.1025,\n",
      "          0.0800,  0.2576],\n",
      "        [-0.0839, -0.2230, -0.1228, -0.0858,  0.0704,  0.0710, -0.1071,  0.0589,\n",
      "         -0.1921, -0.2351],\n",
      "        [-0.2625,  0.1542, -0.1768,  0.3035,  0.1953,  0.1973,  0.1517, -0.0912,\n",
      "          0.2466,  0.0516],\n",
      "        [-0.3125,  0.1076,  0.2082, -0.3138, -0.0640, -0.2924,  0.1090, -0.2874,\n",
      "          0.1780, -0.2514],\n",
      "        [ 0.2394,  0.0782, -0.1326, -0.0098,  0.0624,  0.2265, -0.0611,  0.0950,\n",
      "         -0.0236, -0.1109],\n",
      "        [ 0.0040, -0.2577,  0.0679,  0.1062,  0.0894, -0.2055, -0.2988,  0.1236,\n",
      "         -0.0570, -0.1466],\n",
      "        [ 0.3149,  0.2359,  0.1590,  0.0936,  0.2787,  0.2053, -0.0488, -0.1447,\n",
      "          0.2216,  0.1051],\n",
      "        [-0.0189, -0.2028,  0.2359, -0.1947, -0.0017,  0.2760, -0.3040, -0.0487,\n",
      "         -0.2360, -0.2166],\n",
      "        [-0.2693,  0.0925,  0.2331, -0.0310, -0.0596,  0.1471, -0.1936, -0.2030,\n",
      "         -0.0020,  0.3077]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2785, -0.3095,  0.0434,  0.2089, -0.2266, -0.2284,  0.1489, -0.0727,\n",
      "        -0.0139, -0.1970], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1536, -0.1595,  0.2589, -0.0277, -0.1033,  0.2342,  0.1021,  0.2462,\n",
      "          0.0286, -0.2817],\n",
      "        [ 0.0197,  0.2423, -0.2986, -0.1016,  0.2652, -0.2865, -0.0167, -0.0915,\n",
      "          0.0711, -0.0540],\n",
      "        [-0.0268,  0.1358, -0.2856,  0.0848, -0.3030,  0.2956, -0.0208,  0.2506,\n",
      "         -0.1655,  0.1698],\n",
      "        [-0.2814, -0.0010,  0.1761, -0.2876,  0.1898,  0.2782, -0.1986, -0.2749,\n",
      "          0.0225,  0.2540],\n",
      "        [ 0.0083,  0.2699, -0.0644,  0.2479, -0.1745, -0.2201, -0.1453,  0.1163,\n",
      "          0.2129,  0.2414],\n",
      "        [ 0.1470,  0.1835, -0.0088,  0.1883, -0.1781, -0.1279,  0.2465,  0.1883,\n",
      "          0.1657,  0.1658],\n",
      "        [ 0.0746,  0.1458, -0.0787, -0.2266,  0.1474, -0.2323, -0.1241,  0.0814,\n",
      "          0.2554, -0.2176],\n",
      "        [ 0.0525,  0.0716, -0.1324, -0.2593,  0.1071,  0.0705,  0.2382,  0.0287,\n",
      "          0.1031,  0.2378]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1612, -0.1467, -0.0302, -0.0161,  0.2023,  0.3154, -0.1725,  0.0235],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0894, -0.1223, -0.0616, -0.2165, -0.0115,  0.0670, -0.1872, -0.0819],\n",
      "        [-0.3190,  0.2732,  0.1517, -0.2448, -0.3306,  0.3439,  0.1301, -0.2391],\n",
      "        [-0.0985, -0.3497,  0.0391,  0.1500, -0.0525,  0.1006, -0.0111, -0.0117],\n",
      "        [-0.3253, -0.0952,  0.0691, -0.1748, -0.0821, -0.0792,  0.2651, -0.2041],\n",
      "        [-0.0402,  0.0421,  0.1003,  0.2556, -0.3248, -0.1830,  0.3529,  0.0390],\n",
      "        [-0.0382, -0.0501, -0.0126, -0.1681,  0.0554, -0.2807, -0.0274, -0.0387]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3895, -0.1066, -0.3116,  0.2544,  0.1283,  0.1787],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2711, -0.0147,  0.3405, -0.3522,  0.3192,  0.0914]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0777], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for index in range(nb_epochs):\n",
    "    indices = torch.randperm(x.size(0))\n",
    "    \n",
    "    # create minibatch data\n",
    "    x_batch_list = torch.index_select(x, 0, indices)\n",
    "    y_batch_list = torch.index_select(y, 0, indices)\n",
    "    x_batch_list = x_batch_list.split(minibatch_size, 0)\n",
    "    y_batch_list = y_batch_list.split(minibatch_size, 0)\n",
    "    \n",
    "    for x_minibatch, y_minibatch in zip(x_batch_list, y_batch_list):\n",
    "        y_minibatch_pred = model(x_minibatch)\n",
    "        loss = loss_function(y_minibatch_pred, y_minibatch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "print(loss)\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589776ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
