{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-03</th>\n",
       "      <td>47.47</td>\n",
       "      <td>47.85</td>\n",
       "      <td>46.25</td>\n",
       "      <td>47.58</td>\n",
       "      <td>7582127</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-04</th>\n",
       "      <td>47.48</td>\n",
       "      <td>47.73</td>\n",
       "      <td>46.69</td>\n",
       "      <td>47.25</td>\n",
       "      <td>7440914</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-05</th>\n",
       "      <td>47.16</td>\n",
       "      <td>48.20</td>\n",
       "      <td>47.11</td>\n",
       "      <td>47.65</td>\n",
       "      <td>5417258</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-06</th>\n",
       "      <td>47.97</td>\n",
       "      <td>48.58</td>\n",
       "      <td>47.32</td>\n",
       "      <td>47.87</td>\n",
       "      <td>6154285</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-09</th>\n",
       "      <td>46.55</td>\n",
       "      <td>47.10</td>\n",
       "      <td>46.40</td>\n",
       "      <td>47.08</td>\n",
       "      <td>8945056</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open   High    Low  Close   Volume  Name\n",
       "Date                                                 \n",
       "2006-01-03  47.47  47.85  46.25  47.58  7582127  AMZN\n",
       "2006-01-04  47.48  47.73  46.69  47.25  7440914  AMZN\n",
       "2006-01-05  47.16  48.20  47.11  47.65  5417258  AMZN\n",
       "2006-01-06  47.97  48.58  47.32  47.87  6154285  AMZN\n",
       "2006-01-09  46.55  47.10  46.40  47.08  8945056  AMZN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/AMZN.csv', index_col='Date', parse_dates=True)\n",
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✨MinMaxScaler 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3019, 5) (3019, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "raw_data = deepcopy(df.drop(['Name'], axis=1))\n",
    "X_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "y_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "X_raw_data = X_scaler.fit_transform(raw_data)   # 시가 ~ 종가\n",
    "y_raw_data = y_scaler.fit_transform(raw_data['Close'].values.reshape(-1,1)) # 종가\n",
    "print(X_raw_data.shape, y_raw_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✨X_train 과 y_train 데이터 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_xy(X_raw_data, y_raw_data, lookback):\n",
    "    data = list()\n",
    "    for index in range(len(X_raw_data)-lookback):\n",
    "        data.append(X_raw_data[index:index+lookback])\n",
    "    data = np.array(data)\n",
    "    return data, y_raw_data[lookback:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3009, 10, 5]) torch.Size([3009, 1])\n"
     ]
    }
   ],
   "source": [
    "lookback = 10 # sequence length - 1\n",
    "X_train, y_train = prepare_xy(X_raw_data, y_raw_data, lookback)\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✨Custom Dataet\n",
    "> raw data를 텐서로 만들어, 전체 데이터를 딥러닝 모델에 한번에 넣는 경우는 없으므로, 미니배치를 쉽게 구성하고, 반복문을 통해, 미니 배치 하나씩 가져오도록 하는 구성이 필요함. 이를 손쉽게 해주는 기능이 Subset, DataLoader 등의 기능이며, 이를 위해, raw data를 Dataset으로 만들어주어야 함"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✨Custom Dataset class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.utils.data.Dataset 클래스 상속\n",
    "- 다음 세가지 메서드가 필요\n",
    "    - _ _init_ _(self) : 입력 데이터(x)와 실제 값(y)을 선언해주는 메서드\n",
    "    - _ _len_ _(self) : 입력 데이터(x)와 실제 값(y) 길이를 리턴해주는 메서드\n",
    "    - _ _getitem_ _(self, index) : index번째 입력 데이터(x)와 실제 값(y)을 리턴해주는 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.X_data = X_train\n",
    "        self.y_data = y_train\n",
    "\n",
    "        # 총 데이터의 개수 리턴\n",
    "        def __len__(self):\n",
    "            return len(self.X_data)\n",
    "        \n",
    "        # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "        def __getitem__(self, index):\n",
    "            X = self.X_data[index]\n",
    "            y = self.y_data[index]\n",
    "            return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rawdata = CustomDataset()\n",
    "train_rawdata.y_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✨TensorDataset\n",
    "- TensorDataset은 Dataset을 상속한 클래스로 학습 데이터 X와 실제 값 Y를 묶어 놓은 Dataset\n",
    "- TensorDataset으로 랩핑한 Dataset은 DataLoader로 미니배치를 쉽게 작성할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rawdata = TensorDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3009, 10, 5])\n",
      "torch.Size([3009, 1])\n"
     ]
    }
   ],
   "source": [
    "print(train_rawdata.tensors[0].shape)   # X_train\n",
    "print(train_rawdata.tensors[1].shape)   # y_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✨Generate Train & Validation Mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_RATE = 0.2\n",
    "train_indices, val_indices = train_test_split(\n",
    "    range(len(train_rawdata)),  # X 인덱스 번호\n",
    "    test_size=VALIDATION_RATE   # test dataset 비율\n",
    ")\n",
    "train_dataset = Subset(train_rawdata, train_indices)\n",
    "validation_dataset = Subset(train_rawdata, val_indices)\n",
    "\n",
    "minibatch_size = 128\n",
    "\n",
    "train_batches = DataLoader(train_dataset, batch_size=minibatch_size, shuffle=True)\n",
    "val_batches = DataLoader(validation_dataset, batch_size=minibatch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10, 5]) torch.Size([128, 1])\n"
     ]
    }
   ],
   "source": [
    "# 미니배치 하나만 불러와서 이미지 Visualization\n",
    "X_train, y_train = next(iter(train_batches))\n",
    "print(X_train.shape, y_train.shape)\n",
    "# ([minibatch_size,sequence,종가]) ([minibatch_size,종가예측])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✨모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, feature_size, hidden_size, num_layers, dropout_p, output_size, model_type='LSTM'):\n",
    "        super().__init__()\n",
    "        if model_type == 'LSTM':\n",
    "            self.sequenceclassifier = nn.LSTM(\n",
    "                input_size=feature_size,\n",
    "                hidden_size=hidden_size,\n",
    "                num_layers=num_layers,\n",
    "                batch_first=True,\n",
    "                dropout=dropout_p\n",
    "            )\n",
    "        elif model_type == 'GRU':\n",
    "            self.sequenceclassifier = nn.GRU(\n",
    "                input_size=feature_size,\n",
    "                hidden_size=hidden_size,\n",
    "                num_layers=num_layers,\n",
    "                batch_first=True,\n",
    "                dropout=dropout_p\n",
    "            )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, _ = self.sequenceclassifier(x)  # |output|=(128, 10, 32)\n",
    "        output = output[:, -1, :]   # |output|=(128, 32)\n",
    "        y = self.fc(output)\n",
    "        return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✨input, output, loss, optimizer 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m model \u001b[39m=\u001b[39m Net(feature_size, hidden_size, num_layers, dropout_p, output_size, \u001b[39m'\u001b[39m\u001b[39mGRU\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m loss_func \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[1;32m----> 9\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mAdam(model\u001b[39m.\u001b[39;49mparameters())\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\DL\\lib\\site-packages\\torch\\optim\\adam.py:33\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid weight_decay value: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(weight_decay))\n\u001b[0;32m     29\u001b[0m defaults \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(lr\u001b[39m=\u001b[39mlr, betas\u001b[39m=\u001b[39mbetas, eps\u001b[39m=\u001b[39meps,\n\u001b[0;32m     30\u001b[0m                 weight_decay\u001b[39m=\u001b[39mweight_decay, amsgrad\u001b[39m=\u001b[39mamsgrad,\n\u001b[0;32m     31\u001b[0m                 maximize\u001b[39m=\u001b[39mmaximize, foreach\u001b[39m=\u001b[39mforeach, capturable\u001b[39m=\u001b[39mcapturable,\n\u001b[0;32m     32\u001b[0m                 differentiable\u001b[39m=\u001b[39mdifferentiable, fused\u001b[39m=\u001b[39mfused)\n\u001b[1;32m---> 33\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(params, defaults)\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m fused:\n\u001b[0;32m     36\u001b[0m     \u001b[39mif\u001b[39;00m differentiable:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\DL\\lib\\site-packages\\torch\\optim\\optimizer.py:187\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m    185\u001b[0m param_groups \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(params)\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(param_groups) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 187\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39moptimizer got an empty parameter list\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(param_groups[\u001b[39m0\u001b[39m], \u001b[39mdict\u001b[39m):\n\u001b[0;32m    189\u001b[0m     param_groups \u001b[39m=\u001b[39m [{\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m: param_groups}]\n",
      "\u001b[1;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "feature_size = 5\n",
    "hidden_size = 32\n",
    "num_layers = 2\n",
    "dropout_p = 0\n",
    "output_size = 1\n",
    "\n",
    "model = Net(feature_size, hidden_size, num_layers, dropout_p, output_size, 'GRU')\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
