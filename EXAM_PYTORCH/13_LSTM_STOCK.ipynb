{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-03</th>\n",
       "      <td>47.47</td>\n",
       "      <td>47.85</td>\n",
       "      <td>46.25</td>\n",
       "      <td>47.58</td>\n",
       "      <td>7582127</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-04</th>\n",
       "      <td>47.48</td>\n",
       "      <td>47.73</td>\n",
       "      <td>46.69</td>\n",
       "      <td>47.25</td>\n",
       "      <td>7440914</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-05</th>\n",
       "      <td>47.16</td>\n",
       "      <td>48.20</td>\n",
       "      <td>47.11</td>\n",
       "      <td>47.65</td>\n",
       "      <td>5417258</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-06</th>\n",
       "      <td>47.97</td>\n",
       "      <td>48.58</td>\n",
       "      <td>47.32</td>\n",
       "      <td>47.87</td>\n",
       "      <td>6154285</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-09</th>\n",
       "      <td>46.55</td>\n",
       "      <td>47.10</td>\n",
       "      <td>46.40</td>\n",
       "      <td>47.08</td>\n",
       "      <td>8945056</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open   High    Low  Close   Volume  Name\n",
       "Date                                                 \n",
       "2006-01-03  47.47  47.85  46.25  47.58  7582127  AMZN\n",
       "2006-01-04  47.48  47.73  46.69  47.25  7440914  AMZN\n",
       "2006-01-05  47.16  48.20  47.11  47.65  5417258  AMZN\n",
       "2006-01-06  47.97  48.58  47.32  47.87  6154285  AMZN\n",
       "2006-01-09  46.55  47.10  46.40  47.08  8945056  AMZN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/AMZN.csv', index_col='Date', parse_dates=True)\n",
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✨MinMaxScaler 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3019, 5) (3019, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "raw_data = deepcopy(df.drop(['Name'], axis=1))\n",
    "X_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "y_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "X_raw_data = X_scaler.fit_transform(raw_data)   # 시가 ~ 종가\n",
    "y_raw_data = y_scaler.fit_transform(raw_data['Close'].values.reshape(-1,1)) # 종가\n",
    "print(X_raw_data.shape, y_raw_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✨X_train 과 y_train 데이터 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_xy(X_raw_data, y_raw_data, lookback):\n",
    "    data = list()\n",
    "    for index in range(len(X_raw_data)-lookback):\n",
    "        data.append(X_raw_data[index:index+lookback])\n",
    "    data = np.array(data)\n",
    "    return data, y_raw_data[lookback:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3009, 10, 5]) torch.Size([3009, 1])\n"
     ]
    }
   ],
   "source": [
    "lookback = 10 # sequence length - 1\n",
    "X_train, y_train = prepare_xy(X_raw_data, y_raw_data, lookback)\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✨Custom Dataet\n",
    "> raw data를 텐서로 만들어, 전체 데이터를 딥러닝 모델에 한번에 넣는 경우는 없으므로, 미니배치를 쉽게 구성하고, 반복문을 통해, 미니 배치 하나씩 가져오도록 하는 구성이 필요함. 이를 손쉽게 해주는 기능이 Subset, DataLoader 등의 기능이며, 이를 위해, raw data를 Dataset으로 만들어주어야 함"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✨Custom Dataset class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.utils.data.Dataset 클래스 상속\n",
    "- 다음 세가지 메서드가 필요\n",
    "    - _ _init_ _(self) : 입력 데이터(x)와 실제 값(y)을 선언해주는 메서드\n",
    "    - _ _len_ _(self) : 입력 데이터(x)와 실제 값(y) 길이를 리턴해주는 메서드\n",
    "    - _ _getitem_ _(self, index) : index번째 입력 데이터(x)와 실제 값(y)을 리턴해주는 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.X_data = X_train\n",
    "        self.y_data = y_train\n",
    "\n",
    "        # 총 데이터의 개수 리턴\n",
    "        def __len__(self):\n",
    "            return len(self.X_data)\n",
    "        \n",
    "        # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "        def __getitem__(self, index):\n",
    "            X = self.X_data[index]\n",
    "            y = self.y_data[index]\n",
    "            return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rawdata = CustomDataset()\n",
    "train_rawdata.y_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✨TensorDataset\n",
    "- TensorDataset은 Dataset을 상속한 클래스로 학습 데이터 X와 실제 값 Y를 묶어 놓은 Dataset\n",
    "- TensorDataset으로 랩핑한 Dataset은 DataLoader로 미니배치를 쉽게 작성할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rawdata = TensorDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3009, 10, 5])\n",
      "torch.Size([3009, 1])\n"
     ]
    }
   ],
   "source": [
    "print(train_rawdata.tensors[0].shape)   # X_train\n",
    "print(train_rawdata.tensors[1].shape)   # y_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✨Generate Train & Validation Mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_RATE = 0.2\n",
    "train_indices, val_indices = train_test_split(\n",
    "    range(len(train_rawdata)),  # X 인덱스 번호\n",
    "    test_size=VALIDATION_RATE   # test dataset 비율\n",
    ")\n",
    "train_dataset = Subset(train_rawdata, train_indices)\n",
    "validation_dataset = Subset(train_rawdata, val_indices)\n",
    "\n",
    "minibatch_size = 128\n",
    "\n",
    "train_batches = DataLoader(train_dataset, batch_size=minibatch_size, shuffle=True)\n",
    "val_batches = DataLoader(validation_dataset, batch_size=minibatch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10, 5]) torch.Size([128, 1])\n"
     ]
    }
   ],
   "source": [
    "# 미니배치 하나만 불러와서 이미지 Visualization\n",
    "X_train, y_train = next(iter(train_batches))\n",
    "print(X_train.shape, y_train.shape)\n",
    "# ([minibatch_size,sequence,종가]) ([minibatch_size,종가예측])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✨모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, feature_size, hidden_size, num_layers, dropout_p, output_size, model_type='LSTM'):\n",
    "        super().__init__()\n",
    "        if model_type == 'LSTM':\n",
    "            self.sequenceclassifier = nn.LSTM(\n",
    "                input_size=feature_size,\n",
    "                hidden_size=hidden_size,\n",
    "                num_layers=num_layers,\n",
    "                batch_first=True,\n",
    "                dropout=dropout_p\n",
    "            )\n",
    "        elif model_type == 'GRU':\n",
    "            self.sequenceclassifier = nn.GRU(\n",
    "                input_size=feature_size,\n",
    "                hidden_size=hidden_size,\n",
    "                num_layers=num_layers,\n",
    "                batch_first=True,\n",
    "                dropout=dropout_p\n",
    "            )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, _ = self.sequenceclassifier(x)  # |output|=(128, 10, 32)\n",
    "        output = output[:, -1, :]   # |output|=(128, 32)\n",
    "        y = self.fc(output)\n",
    "        return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✨input, output, loss, optimizer 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 5    # input dimension\n",
    "hidden_size = 32    # Hidden Layer\n",
    "num_layers = 2      # stacked RNN\n",
    "dropout_p = 0\n",
    "output_size = 1\n",
    "\n",
    "model = Net(feature_size, hidden_size, num_layers, dropout_p, output_size, 'GRU')\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✨Training 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, early_stop, n_epochs, progress_interval):\n",
    "    \n",
    "    train_losses, valid_losses, lowest_loss = list(), list(), np.inf\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for x_minibatch, y_minibatch in train_batches:\n",
    "            y_minibatch_pred = model(x_minibatch)\n",
    "            loss = loss_func(y_minibatch_pred, y_minibatch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        # validate the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_minibatch, y_minibatch in val_batches:\n",
    "                y_minibatch_pred = model(x_minibatch)\n",
    "                loss = loss_func(y_minibatch_pred, y_minibatch)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                valid_losses.append(loss.item())\n",
    "            \n",
    "            if valid_losses[-1] < lowest_loss:\n",
    "                lowest_loss = valid_losses[-1]\n",
    "                lowest_epoch = epoch\n",
    "                best_model = deepcopy(model.state_dict())\n",
    "            else:\n",
    "                if (early_stop < 0)\n",
    "\n",
    "    print(train_losses[-1], valid_losses[-1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
