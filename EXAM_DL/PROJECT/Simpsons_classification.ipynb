{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, Conv2D, MaxPooling2D, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'splitfolders'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msplitfolders\u001b[39;00m\n\u001b[0;32m      3\u001b[0m input_dir \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDATA\u001b[39m\u001b[39m\\\u001b[39m\u001b[39msimpsons_dataset\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      4\u001b[0m output_dir \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDATA\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'splitfolders'"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "\n",
    "input_dir = r'C:\\DATA\\simpsons_dataset'\n",
    "output_dir = r'C:\\DATA\\data'\n",
    "\n",
    "splitfolders.ratio(input_dir, output=output_dir, seed=1337, ratio=(.8, .1, .1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r'C:\\DATA\\data\\train'\n",
    "val_dir = r'C:\\DATA\\data\\val'\n",
    "test_dir = r'C:\\DATA\\data\\test'\n",
    "\n",
    "image_size = (64, 64, 3)\n",
    "epochs = 50\n",
    "batch_size = \n",
    "\n",
    "labels = os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abraham_grampa_simpson',\n",
       " 'agnes_skinner',\n",
       " 'apu_nahasapeemapetilon',\n",
       " 'barney_gumble',\n",
       " 'bart_simpson',\n",
       " 'carl_carlson',\n",
       " 'charles_montgomery_burns',\n",
       " 'chief_wiggum',\n",
       " 'cletus_spuckler',\n",
       " 'comic_book_guy',\n",
       " 'disco_stu',\n",
       " 'edna_krabappel',\n",
       " 'fat_tony',\n",
       " 'gil',\n",
       " 'groundskeeper_willie',\n",
       " 'homer_simpson',\n",
       " 'kent_brockman',\n",
       " 'krusty_the_clown',\n",
       " 'lenny_leonard',\n",
       " 'lionel_hutz',\n",
       " 'lisa_simpson',\n",
       " 'maggie_simpson',\n",
       " 'marge_simpson',\n",
       " 'martin_prince',\n",
       " 'mayor_quimby',\n",
       " 'milhouse_van_houten',\n",
       " 'miss_hoover',\n",
       " 'moe_szyslak',\n",
       " 'ned_flanders',\n",
       " 'nelson_muntz',\n",
       " 'otto_mann',\n",
       " 'patty_bouvier',\n",
       " 'principal_skinner',\n",
       " 'professor_john_frink',\n",
       " 'rainier_wolfcastle',\n",
       " 'ralph_wiggum',\n",
       " 'selma_bouvier',\n",
       " 'sideshow_bob',\n",
       " 'sideshow_mel',\n",
       " 'simpsons_dataset',\n",
       " 'snake_jailbird',\n",
       " 'troy_mcclure',\n",
       " 'waylon_smithers']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16727 images belonging to 43 classes.\n",
      "Found 2073 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(train_dir,\n",
    "                                                 target_size = image_size[:2],\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode = 'sparse',\n",
    "                                                 color_mode = 'rgb')\n",
    "\n",
    "val_set = test_datagen.flow_from_directory(val_dir,\n",
    "                                           target_size = image_size[:2],\n",
    "                                           batch_size=batch_size,\n",
    "                                           class_mode = 'sparse',\n",
    "                                           color_mode = 'rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=image_size))\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same', activation = 'relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(labels), activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=image_size)\n",
    "\n",
    "x1 = Conv2D(32, (3, 3), padding = 'same', activation = 'relu')(input_layer)\n",
    "x2 = Conv2D(32, (3, 3), activation = 'relu')(x1)\n",
    "x3 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "x4 = Dropout(0.2)(x3)\n",
    "x5 = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(x4)\n",
    "x6 = MaxPooling2D(pool_size=(2, 2))(x5)\n",
    "x7 = Dropout(0.2)(x6)\n",
    "x8 = Conv2D(256, (3, 3), padding = 'same', activation = 'relu')(x7)\n",
    "x9 = MaxPooling2D(pool_size=(2, 2))(x8)\n",
    "x10 = Dropout(0.2)(x9)\n",
    "x11 = Flatten()(x10)\n",
    "x12 = Dense(1024, activation = 'relu')(x11)\n",
    "x13 = Dropout(0.5)(x12)\n",
    "x14 = Dense(len(labels), activation = 'softmax')(x13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopCB = EarlyStopping(monitor='val_acc', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 62, 62, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 31, 31, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 31, 31, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 15, 15, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 15, 15, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 256)       147712    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 7, 7, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              12846080  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 43)                44075     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,066,507\n",
      "Trainable params: 13,066,507\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopCB = EarlyStopping(patience=5, monitor='val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "168/168 [==============================] - 134s 798ms/step - loss: 2.4731 - acc: 0.3095 - val_loss: 1.8109 - val_acc: 0.5094\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 152s 906ms/step - loss: 2.0301 - acc: 0.4399 - val_loss: 1.4644 - val_acc: 0.5914\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 143s 849ms/step - loss: 1.7156 - acc: 0.5223 - val_loss: 1.1291 - val_acc: 0.6855\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 134s 796ms/step - loss: 1.4806 - acc: 0.5874 - val_loss: 1.0284 - val_acc: 0.7106\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 142s 843ms/step - loss: 1.2964 - acc: 0.6379 - val_loss: 0.8225 - val_acc: 0.7646\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 100s 594ms/step - loss: 1.1774 - acc: 0.6724 - val_loss: 0.7150 - val_acc: 0.8013\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 144s 859ms/step - loss: 1.0928 - acc: 0.6895 - val_loss: 0.6681 - val_acc: 0.8114\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 132s 785ms/step - loss: 1.0268 - acc: 0.7099 - val_loss: 0.6262 - val_acc: 0.8278\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 135s 801ms/step - loss: 0.9437 - acc: 0.7356 - val_loss: 0.6245 - val_acc: 0.8225\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 133s 796ms/step - loss: 0.9073 - acc: 0.7428 - val_loss: 0.5939 - val_acc: 0.8321\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 141s 842ms/step - loss: 0.8509 - acc: 0.7609 - val_loss: 0.5143 - val_acc: 0.8548\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 140s 835ms/step - loss: 0.8274 - acc: 0.7664 - val_loss: 0.5076 - val_acc: 0.8596\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 142s 844ms/step - loss: 0.7928 - acc: 0.7736 - val_loss: 0.4806 - val_acc: 0.8678\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 132s 787ms/step - loss: 0.7744 - acc: 0.7861 - val_loss: 0.4868 - val_acc: 0.8620\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 132s 788ms/step - loss: 0.7452 - acc: 0.7854 - val_loss: 0.4738 - val_acc: 0.8664\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 136s 809ms/step - loss: 0.7282 - acc: 0.7936 - val_loss: 0.4640 - val_acc: 0.8693\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 131s 782ms/step - loss: 0.6784 - acc: 0.8059 - val_loss: 0.4328 - val_acc: 0.8775\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 129s 768ms/step - loss: 0.6754 - acc: 0.8077 - val_loss: 0.4416 - val_acc: 0.8746\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 146s 869ms/step - loss: 0.6543 - acc: 0.8105 - val_loss: 0.4372 - val_acc: 0.8746\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 158s 940ms/step - loss: 0.6398 - acc: 0.8196 - val_loss: 0.4239 - val_acc: 0.8842\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 140s 833ms/step - loss: 0.6201 - acc: 0.8263 - val_loss: 0.4243 - val_acc: 0.8905\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 126s 753ms/step - loss: 0.6047 - acc: 0.8220 - val_loss: 0.4005 - val_acc: 0.8924\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 125s 743ms/step - loss: 0.5806 - acc: 0.8341 - val_loss: 0.3642 - val_acc: 0.9030\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 127s 754ms/step - loss: 0.5920 - acc: 0.8319 - val_loss: 0.4083 - val_acc: 0.8905\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 117s 694ms/step - loss: 0.5881 - acc: 0.8326 - val_loss: 0.3779 - val_acc: 0.9030\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 120s 713ms/step - loss: 0.5634 - acc: 0.8383 - val_loss: 0.3682 - val_acc: 0.9093\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 124s 738ms/step - loss: 0.5567 - acc: 0.8407 - val_loss: 0.3829 - val_acc: 0.9035\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 132s 783ms/step - loss: 0.5548 - acc: 0.8410 - val_loss: 0.3366 - val_acc: 0.9170\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 142s 847ms/step - loss: 0.5269 - acc: 0.8499 - val_loss: 0.3561 - val_acc: 0.9093\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 132s 783ms/step - loss: 0.5244 - acc: 0.8485 - val_loss: 0.3362 - val_acc: 0.9093\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 127s 755ms/step - loss: 0.5236 - acc: 0.8492 - val_loss: 0.3786 - val_acc: 0.9016\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 112s 666ms/step - loss: 0.5131 - acc: 0.8517 - val_loss: 0.3217 - val_acc: 0.9141\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 110s 654ms/step - loss: 0.5018 - acc: 0.8572 - val_loss: 0.3493 - val_acc: 0.9132\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_set,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = val_set,\n",
    "                    callbacks = [stopCB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.473080</td>\n",
       "      <td>0.309500</td>\n",
       "      <td>1.810910</td>\n",
       "      <td>0.509407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.030052</td>\n",
       "      <td>0.439888</td>\n",
       "      <td>1.464407</td>\n",
       "      <td>0.591413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.715649</td>\n",
       "      <td>0.522269</td>\n",
       "      <td>1.129146</td>\n",
       "      <td>0.685480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.480553</td>\n",
       "      <td>0.587374</td>\n",
       "      <td>1.028398</td>\n",
       "      <td>0.710564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.296354</td>\n",
       "      <td>0.637891</td>\n",
       "      <td>0.822520</td>\n",
       "      <td>0.764592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.177423</td>\n",
       "      <td>0.672386</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.801254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.092765</td>\n",
       "      <td>0.689484</td>\n",
       "      <td>0.668057</td>\n",
       "      <td>0.811384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.026778</td>\n",
       "      <td>0.709870</td>\n",
       "      <td>0.626178</td>\n",
       "      <td>0.827786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.943656</td>\n",
       "      <td>0.735577</td>\n",
       "      <td>0.624540</td>\n",
       "      <td>0.822479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.907322</td>\n",
       "      <td>0.742811</td>\n",
       "      <td>0.593891</td>\n",
       "      <td>0.832127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.850869</td>\n",
       "      <td>0.760866</td>\n",
       "      <td>0.514287</td>\n",
       "      <td>0.854800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.827434</td>\n",
       "      <td>0.766366</td>\n",
       "      <td>0.507557</td>\n",
       "      <td>0.859624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.792828</td>\n",
       "      <td>0.773600</td>\n",
       "      <td>0.480645</td>\n",
       "      <td>0.867824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.774398</td>\n",
       "      <td>0.786094</td>\n",
       "      <td>0.486808</td>\n",
       "      <td>0.862036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.745158</td>\n",
       "      <td>0.785377</td>\n",
       "      <td>0.473775</td>\n",
       "      <td>0.866377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.728163</td>\n",
       "      <td>0.793567</td>\n",
       "      <td>0.464025</td>\n",
       "      <td>0.869272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.678356</td>\n",
       "      <td>0.805942</td>\n",
       "      <td>0.432843</td>\n",
       "      <td>0.877472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.675448</td>\n",
       "      <td>0.807676</td>\n",
       "      <td>0.441568</td>\n",
       "      <td>0.874578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.654283</td>\n",
       "      <td>0.810546</td>\n",
       "      <td>0.437196</td>\n",
       "      <td>0.874578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.639786</td>\n",
       "      <td>0.819573</td>\n",
       "      <td>0.423894</td>\n",
       "      <td>0.884226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.620086</td>\n",
       "      <td>0.826329</td>\n",
       "      <td>0.424347</td>\n",
       "      <td>0.890497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.604707</td>\n",
       "      <td>0.821965</td>\n",
       "      <td>0.400482</td>\n",
       "      <td>0.892426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.580618</td>\n",
       "      <td>0.834101</td>\n",
       "      <td>0.364184</td>\n",
       "      <td>0.903039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.591956</td>\n",
       "      <td>0.831948</td>\n",
       "      <td>0.408276</td>\n",
       "      <td>0.890497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.588132</td>\n",
       "      <td>0.832606</td>\n",
       "      <td>0.377859</td>\n",
       "      <td>0.903039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.563444</td>\n",
       "      <td>0.838285</td>\n",
       "      <td>0.368229</td>\n",
       "      <td>0.909310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.556728</td>\n",
       "      <td>0.840737</td>\n",
       "      <td>0.382864</td>\n",
       "      <td>0.903521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.554831</td>\n",
       "      <td>0.841035</td>\n",
       "      <td>0.336568</td>\n",
       "      <td>0.917028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.526853</td>\n",
       "      <td>0.849943</td>\n",
       "      <td>0.356106</td>\n",
       "      <td>0.909310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.524415</td>\n",
       "      <td>0.848508</td>\n",
       "      <td>0.336199</td>\n",
       "      <td>0.909310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.523557</td>\n",
       "      <td>0.849226</td>\n",
       "      <td>0.378565</td>\n",
       "      <td>0.901592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.513148</td>\n",
       "      <td>0.851677</td>\n",
       "      <td>0.321743</td>\n",
       "      <td>0.914134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.501770</td>\n",
       "      <td>0.857177</td>\n",
       "      <td>0.349294</td>\n",
       "      <td>0.913169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss       acc  val_loss   val_acc\n",
       "0   2.473080  0.309500  1.810910  0.509407\n",
       "1   2.030052  0.439888  1.464407  0.591413\n",
       "2   1.715649  0.522269  1.129146  0.685480\n",
       "3   1.480553  0.587374  1.028398  0.710564\n",
       "4   1.296354  0.637891  0.822520  0.764592\n",
       "5   1.177423  0.672386  0.715000  0.801254\n",
       "6   1.092765  0.689484  0.668057  0.811384\n",
       "7   1.026778  0.709870  0.626178  0.827786\n",
       "8   0.943656  0.735577  0.624540  0.822479\n",
       "9   0.907322  0.742811  0.593891  0.832127\n",
       "10  0.850869  0.760866  0.514287  0.854800\n",
       "11  0.827434  0.766366  0.507557  0.859624\n",
       "12  0.792828  0.773600  0.480645  0.867824\n",
       "13  0.774398  0.786094  0.486808  0.862036\n",
       "14  0.745158  0.785377  0.473775  0.866377\n",
       "15  0.728163  0.793567  0.464025  0.869272\n",
       "16  0.678356  0.805942  0.432843  0.877472\n",
       "17  0.675448  0.807676  0.441568  0.874578\n",
       "18  0.654283  0.810546  0.437196  0.874578\n",
       "19  0.639786  0.819573  0.423894  0.884226\n",
       "20  0.620086  0.826329  0.424347  0.890497\n",
       "21  0.604707  0.821965  0.400482  0.892426\n",
       "22  0.580618  0.834101  0.364184  0.903039\n",
       "23  0.591956  0.831948  0.408276  0.890497\n",
       "24  0.588132  0.832606  0.377859  0.903039\n",
       "25  0.563444  0.838285  0.368229  0.909310\n",
       "26  0.556728  0.840737  0.382864  0.903521\n",
       "27  0.554831  0.841035  0.336568  0.917028\n",
       "28  0.526853  0.849943  0.356106  0.909310\n",
       "29  0.524415  0.848508  0.336199  0.909310\n",
       "30  0.523557  0.849226  0.378565  0.901592\n",
       "31  0.513148  0.851677  0.321743  0.914134\n",
       "32  0.501770  0.857177  0.349294  0.913169"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
